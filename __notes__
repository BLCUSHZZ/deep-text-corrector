build_corpus
max_len
- encoder_max_len = max(input_lens)
- decoder_max_len -> max(target_lens) or max_len (eval)
- max_size => 50
visualizing attn
tensorboard

- optimization
pack, unpack
- seq2seq에 적용 가능하나? pack시 정렬하는 문제 때문에.
- 결국 bucketting?

dataset
 - nucle
 - lang8

approach
 - char-level
 - word-level

beam search
---
refactoring
- cuda() 자동으로
- # -*- coding: utf-8 -*-

---
pytorch
=> 더 편하게 쓸 수 있도록 더 개발되어야 한다.
- 손이 많이 간다. gpu사용하려면 cuda() 붙어야 한다. model save/load할때 불편하다. torch, variable, numpy간 타입 변환의 불편함..
- api가 확장성이 떨어진다. tensor의 shape가 특정 형태로 고정되어 있어야만 한다거나..

=> dynamic graph definition 이게 거의 유일한 장점인듯